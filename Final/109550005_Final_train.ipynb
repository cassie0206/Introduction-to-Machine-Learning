{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOoDf2zukKDcf2JMefkLMXT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install flaml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPSidbcd56-W","executionInfo":{"status":"ok","timestamp":1673004218249,"user_tz":-480,"elapsed":6210,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"0e05e0b7-6059-4b21-9544-595a633dd2d6"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting flaml\n","  Downloading FLAML-1.1.0-py3-none-any.whl (216 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.0/216.0 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.3.5)\n","Collecting lightgbm>=2.3.1\n","  Downloading lightgbm-3.3.4-py3-none-manylinux1_x86_64.whl (2.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.8/dist-packages (from flaml) (0.90)\n","Requirement already satisfied: scikit-learn>=0.24 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.0.2)\n","Requirement already satisfied: NumPy>=1.17.0rc1 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.21.6)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from flaml) (1.7.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from lightgbm>=2.3.1->flaml) (0.38.4)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->flaml) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->flaml) (2022.7)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.24->flaml) (1.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.1.4->flaml) (1.15.0)\n","Installing collected packages: lightgbm, flaml\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 2.2.3\n","    Uninstalling lightgbm-2.2.3:\n","      Successfully uninstalled lightgbm-2.2.3\n","Successfully installed flaml-1.1.0 lightgbm-3.3.4\n"]}]},{"cell_type":"code","source":["# for google colab\n","from google.colab import drive\n","# mount your Google Drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZsbgNZ3yKgs","executionInfo":{"status":"ok","timestamp":1673004238297,"user_tz":-480,"elapsed":20053,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"8c812c85-1abf-4739-9c45-48f06dbbe744"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["# for google colab\n","# copy all files from \"HW5\" directory in Google drive to current directory\n","!cp -r ./gdrive/MyDrive/Final/* ."],"metadata":{"id":"x7KjLIAoyPpv","executionInfo":{"status":"ok","timestamp":1673004241746,"user_tz":-480,"elapsed":3458,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import csv\n","import cv2\n","import random\n","import os\n","\n","import keras\n","from scipy.io import loadmat\n","import matplotlib.pyplot as plt\n","import glob\n","import numpy as np\n","import pandas as pd\n","import math\n","import os\n","from keras.layers import *\n","from keras.models import *\n","from keras.optimizers import *\n","import numpy as np\n","\n","#device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"OFKiwj74ykBl","executionInfo":{"status":"ok","timestamp":1673004248977,"user_tz":-480,"elapsed":7243,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import *\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","import matplotlib.pyplot as plt\n","from matplotlib.pyplot import figure\n","from sklearn.preprocessing import *\n","from sklearn.pipeline import *\n","from sklearn.tree import *\n","from sklearn.metrics import *\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.datasets import make_moons, make_circles, make_classification\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.gaussian_process import GaussianProcessClassifier\n","from sklearn.gaussian_process.kernels import RBF\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n","# from sklearn.inspection import DecisionBoundaryDisplay"],"metadata":{"id":"px0G0Iuy5v4q","executionInfo":{"status":"ok","timestamp":1673004251235,"user_tz":-480,"elapsed":2283,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Data Loading"],"metadata":{"id":"8HzjXnqNx_yy"}},{"cell_type":"code","execution_count":6,"metadata":{"id":"d3CYyWMEogFq","executionInfo":{"status":"ok","timestamp":1673004251236,"user_tz":-480,"elapsed":25,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"outputs":[],"source":["'''\n","train = pd.read_csv('train.csv', index_col = 'id') \n","test = pd.read_csv('test.csv', index_col = 'id')\n","submission = pd.read_csv('sample_submission.csv')\n","\n","# Remove target column\n","target = train['failure'].copy()\n","gc.collect()\n","\n","train.head()\n","'''\n","MANIFEST_DIR = \"train.csv\"\n","TEST_MANIFEST_DIR = \"test.csv\"\n","Batch_size = 500\n","Long = 26570\n","Lens = 21256"]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","def make_preprocessor(dataset):\n","    num_cols = [col for col in dataset if dataset[col].dtype not in ['object']] # numeric type\n","    cat_cols = [col for col in dataset if dataset[col].dtype in ['object']] # category type\n","    num_pipe = Pipeline([\n","      ('impute', SimpleImputer()),\n","      ('scale', MinMaxScaler()),\n","    ])\n","    cat_pipe = Pipeline([\n","      ('encode', OrdinalEncoder())\n","    ])\n","    preprocessor = ColumnTransformer([\n","      ('numeric', num_pipe, num_cols),\n","      ('categorical', cat_pipe, cat_cols),\n","    ])\n","    return preprocessor"],"metadata":{"id":"rx-Rkdup50sJ","executionInfo":{"status":"ok","timestamp":1673004251236,"user_tz":-480,"elapsed":22,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def xs_gen(path=MANIFEST_DIR,batch_size = Batch_size,train=True,Lens=Lens):\n","\n","    #img_list = pd.read_csv(path)\n","    if train:\n","        #img_list = np.array(img_list)[:Lens]\n","        img_list = X[:Lens]\n","        print(\"Found %s train items.\"%len(img_list))\n","        #print(\"list 1 is\",img_list[0,-1])\n","        steps = math.ceil(len(img_list) / batch_size)    # 确定每轮有多少个batch\n","    else:\n","        #img_list = np.array(img_list)[Lens:]\n","        img_list = X[Lens:]\n","        print(\"Found %s test items.\"%len(img_list))\n","        #print(\"list 1 is\",img_list[0,-1])\n","        steps = math.ceil(len(img_list) / batch_size)    # 确定每轮有多少个batch\n","    while True:\n","      for i in range(steps):\n","        batch_list = img_list[i * batch_size : i * batch_size + batch_size]\n","        np.random.shuffle(batch_list)\n","        batch_x = np.array([file for file in batch_list[:,0:-1]])\n","        batch_y = np.array([label for label in batch_list[:,-1]])\n","        #batch_y = np.array([convert2oneHot(label, 2) for label in batch_list[:,-1]])\n","\n","        yield batch_x, batch_y\n"],"metadata":{"id":"7w-7ZN-Pgdlg","executionInfo":{"status":"ok","timestamp":1673004251672,"user_tz":-480,"elapsed":457,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def ts_gen(path=TEST_MANIFEST_DIR,batch_size = Batch_size):\n","\n","    #img_list = pd.read_csv(path)\n","\n","    img_list = X_test[:Lens]\n","    print(\"Found %s train items.\"%len(img_list))\n","    print(\"list 1 is\",img_list[0,-1])\n","    steps = math.ceil(len(img_list) / batch_size)    # 确定每轮有多少个batch\n","    while True:\n","      for i in range(steps):\n","\n","        batch_list = img_list[i * batch_size : i * batch_size + batch_size]\n","        #np.random.shuffle(batch_list)\n","        batch_x = np.array([file for file in batch_list[:,0:]])\n","        #batch_y = np.array([convert2oneHot(label,10) for label in batch_list[:,-1]])\n","\n","        yield batch_x\n"],"metadata":{"id":"wQURtXdjhHp6","executionInfo":{"status":"ok","timestamp":1673004251674,"user_tz":-480,"elapsed":16,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def convert2oneHot(index, Lens):\n","    hot = np.zeros((Lens, ))\n","    hot[int(index)] = 1\n","    return(hot)"],"metadata":{"id":"P4sb94AOY0xC","executionInfo":{"status":"ok","timestamp":1673004251675,"user_tz":-480,"elapsed":15,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv('train.csv')\n","df = df.drop('id', axis=1)\n","df = df.drop('product_code', axis=1)\n","y = df['failure']\n","X = df.drop('failure', axis=1)\n","prep = make_preprocessor(X)\n","X = prep.fit_transform(X)\n","y = np.array(y).reshape(len(y), 1)\n","X = np.append(X, y, axis=1)\n","#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"],"metadata":{"id":"WyTTQhnx6Dnf","executionInfo":{"status":"ok","timestamp":1673004251954,"user_tz":-480,"elapsed":292,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Build Model"],"metadata":{"id":"uwD4CXIlhL7k"}},{"cell_type":"code","source":["TIME_PERIODS = 24\n","def build_model(input_shape=(TIME_PERIODS,),num_classes=1):\n","  model = Sequential()\n","  model.add(Reshape((TIME_PERIODS, 1), input_shape=input_shape))\n","  model.add(Conv1D(filters=32, kernel_size=3, activation='relu',input_shape=(TIME_PERIODS,1)))\n","\n","  model.add(Conv1D(filters=32, kernel_size=3, activation='relu',padding=\"same\"))\n","  model.add(MaxPooling1D(2, padding='same'))\n","\n","  model.add(Conv1D(64, 4,strides=2, activation='relu',padding=\"same\"))\n","  model.add(Conv1D(64, 4,strides=2, activation='relu',padding=\"same\"))\n","  model.add(MaxPooling1D(2, padding='same'))\n","  \n","  model.add(Conv1D(256, 4,strides=2, activation='relu',padding=\"same\"))\n","  model.add(Conv1D(256, 4,strides=2, activation='relu',padding=\"same\"))\n","  model.add(MaxPooling1D(2, padding='same'))\n","  model.add(Conv1D(512, 2,strides=1, activation='relu',padding=\"same\"))\n","  model.add(Conv1D(512, 2,strides=1, activation='relu',padding=\"same\"))\n","  model.add(MaxPooling1D(2, padding='same'))\n","  \n","  \"\"\"model.add(Flatten())\n","  model.add(Dropout(0.3))\n","  model.add(Dense(256, activation='relu'))\"\"\"\n","  model.add(GlobalAveragePooling1D())\n","  model.add(Dropout(0.3))\n","  model.add(Dense(num_classes, activation='sigmoid'))\n","  \n","  return(model)\n"],"metadata":{"id":"bqr9qDN8hO6W","executionInfo":{"status":"ok","timestamp":1673004251954,"user_tz":-480,"elapsed":4,"user":{"displayName":"張可晴","userId":"06130326083553074662"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"PGQ8hhQXhW4z"}},{"cell_type":"code","source":["train_iter = xs_gen()\n","val_iter = xs_gen(train=False)\n","\n","ckpt = keras.callbacks.ModelCheckpoint(\n","    filepath='best_model.{epoch:02d}-{val_loss:.4f}.h5',\n","    monitor='val_loss', save_best_only=True,verbose=1)\n","\n","model = build_model()\n","#model = load_model(\"best_model.10-0.5101.h5\")\n","opt = Adam(0.0002)\n","model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","print(model.summary())\n","\n","model.fit_generator(\n","    generator=train_iter,\n","    steps_per_epoch= Lens//Batch_size,\n","    epochs=20,\n","    initial_epoch=0,\n","    validation_data = val_iter,\n","    validation_steps = (Long - Lens)//Batch_size,\n","    callbacks=[ckpt],\n","    )\n","model.save(\"finishModel.h5\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ibBZN7L5hZ5e","executionInfo":{"status":"error","timestamp":1673004360915,"user_tz":-480,"elapsed":108964,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"outputId":"210a4290-dfcf-4e78-e4a6-49016366f3a0"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," reshape (Reshape)           (None, 24, 1)             0         \n","                                                                 \n"," conv1d (Conv1D)             (None, 9, 16)             144       \n","                                                                 \n"," conv1d_1 (Conv1D)           (None, 5, 16)             2064      \n","                                                                 \n"," max_pooling1d (MaxPooling1D  (None, 3, 16)            0         \n"," )                                                               \n","                                                                 \n"," conv1d_2 (Conv1D)           (None, 2, 64)             4160      \n","                                                                 \n"," conv1d_3 (Conv1D)           (None, 1, 64)             16448     \n","                                                                 \n"," max_pooling1d_1 (MaxPooling  (None, 1, 64)            0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_4 (Conv1D)           (None, 1, 256)            65792     \n","                                                                 \n"," conv1d_5 (Conv1D)           (None, 1, 256)            262400    \n","                                                                 \n"," max_pooling1d_2 (MaxPooling  (None, 1, 256)           0         \n"," 1D)                                                             \n","                                                                 \n"," conv1d_6 (Conv1D)           (None, 1, 512)            262656    \n","                                                                 \n"," conv1d_7 (Conv1D)           (None, 1, 512)            524800    \n","                                                                 \n"," max_pooling1d_3 (MaxPooling  (None, 1, 512)           0         \n"," 1D)                                                             \n","                                                                 \n"," global_average_pooling1d (G  (None, 512)              0         \n"," lobalAveragePooling1D)                                          \n","                                                                 \n"," dropout (Dropout)           (None, 512)               0         \n","                                                                 \n"," dense (Dense)               (None, 1)                 513       \n","                                                                 \n","=================================================================\n","Total params: 1,138,977\n","Trainable params: 1,138,977\n","Non-trainable params: 0\n","_________________________________________________________________\n","None\n","Found 21256 train items.\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-13-d3aaa9b00476>:14: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  model.fit_generator(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","42/42 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7806Found 5314 test items.\n","\n","Epoch 1: val_loss improved from inf to 0.00000, saving model to best_model.01-0.0000.h5\n","42/42 [==============================] - 56s 1s/step - loss: 0.0000e+00 - accuracy: 0.7806 - val_loss: 0.0000e+00 - val_accuracy: 0.7908\n","Epoch 2/20\n","42/42 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.7858\n","Epoch 2: val_loss did not improve from 0.00000\n","42/42 [==============================] - 45s 1s/step - loss: 0.0000e+00 - accuracy: 0.7858 - val_loss: 0.0000e+00 - val_accuracy: 0.7908\n","Epoch 3/20\n"," 4/42 [=>............................] - ETA: 37s - loss: 0.0000e+00 - accuracy: 0.7768"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d3aaa9b00476>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m model.fit_generator(\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLens\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mBatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2258\u001b[0m         \u001b[0;34m'Please use `Model.fit`, which supports generators.'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2259\u001b[0m         stacklevel=2)\n\u001b[0;32m-> 2260\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   2261\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2262\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Testing"],"metadata":{"id":"gGO9Qw9QhqPT"}},{"cell_type":"code","source":["df = pd.read_csv('test.csv')\n","id_ = df['id']\n","df = df.drop('id', axis=1)\n","#df = df.drop('product_code', axis=1)\n","#df = df[['product_code', 'loading', 'attribute_0', 'attribute_1', 'attribute_2',\n","#       'attribute_3', 'measurement_1', 'measurement_5', 'measurement_6',\n","#       'measurement_7', 'measurement_8', 'measurement_17']]\n","print(df.shape)\n","prep = make_preprocessor(df)\n","X_test = prep.fit_transform(df)\n","#print(df.shape)\n","#pred = model.predict_proba(df)[:,1]\n","#result = pd.DataFrame({'id': id_, 'failure': pred})\n","#result.to_csv('submission.csv', index=0)"],"metadata":{"id":"QR30f-23Ypxk","executionInfo":{"status":"ok","timestamp":1673004365367,"user_tz":-480,"elapsed":295,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"00879bbf-3bad-49ec-9a26-5f37968bb576"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["(20775, 24)\n"]}]},{"cell_type":"code","source":["test_iter = ts_gen()\n","#model = load_model(\"best_model.19-0.5106.h5\")\n","pres = model.predict_generator(generator=test_iter,steps=math.ceil(20775/Batch_size),verbose=1)\n","print(pres.shape)\n","#pres.astype('int32')\n","#img_list = pd.read_csv(TEST_MANIFEST_DIR)\n","df = pd.DataFrame()\n","df[\"id\"] = id_\n","df[\"failure\"] = pres\n","df.to_csv(\"submission.csv\",index=None)\n","test_iter = ts_gen()\n","for x in test_iter:\n","    x1 = x[0]\n","    break"],"metadata":{"id":"OB_KOcIzhs1x","executionInfo":{"status":"ok","timestamp":1673004378149,"user_tz":-480,"elapsed":6121,"user":{"displayName":"張可晴","userId":"06130326083553074662"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"72ede83d-0a77-411b-9d58-d71c215fd1f3"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-15-11b0641af291>:3: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n","  pres = model.predict_generator(generator=test_iter,steps=math.ceil(20775/Batch_size),verbose=1)\n"]},{"output_type":"stream","name":"stdout","text":["Found 20775 train items.\n","list 1 is 1.0\n","42/42 [==============================] - 3s 66ms/step\n","(20775, 1)\n","Found 20775 train items.\n","list 1 is 1.0\n"]}]}]}